{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iz7FoNarssE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48fbbc6-934e-4e12-f17c-ceb658b2b928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"git+https://github.com/salaniz/pycocoevalcap.git\""
      ],
      "metadata": {
        "id": "aGWx9AZDrx94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20052d06-4658-4eaf-d89d-022aa9e5d98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/salaniz/pycocoevalcap.git\n",
            "  Cloning https://github.com/salaniz/pycocoevalcap.git to /tmp/pip-req-build-b3_1jvh4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/salaniz/pycocoevalcap.git /tmp/pip-req-build-b3_1jvh4\n",
            "  Resolved https://github.com/salaniz/pycocoevalcap.git to commit a24f74c408c918f1f4ec34e9514bc8a76ce41ffd\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from pycocoevalcap==1.2) (2.0.7)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->pycocoevalcap==1.2) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->pycocoevalcap==1.2) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.16.0)\n",
            "Building wheels for collected packages: pycocoevalcap\n",
            "  Building wheel for pycocoevalcap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocoevalcap: filename=pycocoevalcap-1.2-py3-none-any.whl size=104312246 sha256=ed69637085027f65b67ddd9568d511467db4402eb76309bd96b0262f7f055ff6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_n55olc0/wheels/57/de/9f/7aa9ae75f4e4733cc4b66b5c3a65a05de62a28e8111649fee5\n",
            "Successfully built pycocoevalcap\n",
            "Installing collected packages: pycocoevalcap\n",
            "Successfully installed pycocoevalcap-1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from pycocoevalcap.meteor.meteor import Meteor\n",
        "from pycocoevalcap.bleu.bleu import Bleu\n",
        "from pycocoevalcap.rouge.rouge import Rouge\n",
        "from pycocoevalcap.cider.cider import Cider\n",
        "\n",
        "# The path where MSVD test captions are located (from part4.1):\n",
        "MSVD_test_caps_file = '/content/drive/My Drive/part3_and_4/MSVD_test_captions.json'\n",
        "# The path where relevant MSVD generated test captions are located (from part3):\n",
        "results_file = '/content/drive/My Drive/part3_and_4/MSVD16_1500/MSVD16_1500_test_generated_caps.json'\n",
        "# The json file path where results of evaluation metrics are stored:\n",
        "result_path = '/content/drive/My Drive/part3_and_4/MSVD16_1500/'\n",
        "\n",
        "with open(MSVD_test_caps_file) as file:\n",
        "    actual_caps = json.load(file) # actual caption dataset\n",
        "with open(results_file) as file:\n",
        "    res_caps = json.load(file) # generated captions by relevant models\n",
        "\n",
        "dict_res = {}\n",
        "dict_act = {}\n",
        "for i in range(0, len(actual_caps)):\n",
        "    dict_res[res_caps[i]['video_id']] = [res_caps[i]['caption']]\n",
        "    cap_list = res_caps[i]['caption'].split()\n",
        "    cap_length = len(cap_list)\n",
        "    act_cap = ''\n",
        "    for count in range(0, 15):\n",
        "        for j in range(0,len(actual_caps[i]['captions'])):\n",
        "            if len(actual_caps[i]['captions'][j][0].split()) <= (cap_length + count):\n",
        "                act_cap = actual_caps[i]['captions'][j][0]\n",
        "                break\n",
        "        if act_cap != '':\n",
        "            break\n",
        "    dict_act[actual_caps[i]['video_id']] = [act_cap]\n",
        "\n",
        "Meteor_score, Meteor_scores = Meteor().compute_score(dict_act, dict_res)\n",
        "print(f'Meteor: {Meteor_score*100}')\n",
        "dict_metrics_res = {}\n",
        "dict_metrics_res['Meteor'] = {}\n",
        "dict_metrics_res['Meteor']['Meteor_score'] = Meteor_score\n",
        "dict_metrics_res['Meteor']['Meteor_scores'] = Meteor_scores\n",
        "\n",
        "Bleu_score, Bleu_scores = Bleu(4).compute_score(dict_act, dict_res)\n",
        "for i in range(0, len(Bleu_score)):\n",
        "    print(f'Bleu_{i+1}: {Bleu_score[i]*100}')\n",
        "    dict_metrics_res['Bleu_' + str(i+1)] = {}\n",
        "    dict_metrics_res['Bleu_' + str(i+1)]['Bleu_' + str(i+1) + '_score'] = Bleu_score[i]\n",
        "    dict_metrics_res['Bleu_' + str(i+1)]['Bleu_' + str(i+1) + '_scores'] = Bleu_scores[i]\n",
        "\n",
        "Rouge_score, Rouge_scores = Rouge().compute_score(dict_act, dict_res)\n",
        "print(f'Rouge: {Rouge_score*100}')\n",
        "dict_metrics_res['Rouge'] = {}\n",
        "dict_metrics_res['Rouge']['Rouge_score'] = Rouge_score\n",
        "dict_metrics_res['Rouge']['Rouge_scores'] = Rouge_scores.tolist()\n",
        "\n",
        "Cider_score, Cider_scores = Cider().compute_score(dict_act, dict_res)\n",
        "print(f'Cider: {Cider_score*100}')\n",
        "dict_metrics_res['Cider'] = {}\n",
        "dict_metrics_res['Cider']['Cider_score'] = Cider_score\n",
        "dict_metrics_res['Cider']['Cider_scores'] = Cider_scores.tolist()\n",
        "\n",
        "eval_json = json.dumps(dict_metrics_res, indent = 4)\n",
        "with open(os.path.join(result_path, 'MSVD16_1500_eval_metric_results.json'), 'w') as outfile:\n",
        "    outfile.write(eval_json)"
      ],
      "metadata": {
        "id": "WLbhv27sryUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc499591-fa2b-4b59-82fd-c267a0920a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meteor: 12.120169174763706\n",
            "{'testlen': 3111, 'reflen': 2823, 'guess': [3111, 2441, 1771, 1101], 'correct': [965, 281, 102, 10]}\n",
            "ratio: 1.1020191285862195\n",
            "Bleu_1: 31.018964963024427\n",
            "Bleu_2: 18.896567421835964\n",
            "Bleu_3: 12.716935964685753\n",
            "Bleu_4: 6.574156427129189\n",
            "Rouge: 31.784602716189603\n",
            "Cider: 38.80229023907884\n"
          ]
        }
      ]
    }
  ]
}